{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11297892,"sourceType":"datasetVersion","datasetId":7064883}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:30:37.935459Z","iopub.execute_input":"2025-04-06T13:30:37.935857Z","iopub.status.idle":"2025-04-06T13:30:37.940897Z","shell.execute_reply.started":"2025-04-06T13:30:37.935825Z","shell.execute_reply":"2025-04-06T13:30:37.939825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:30:46.130103Z","iopub.execute_input":"2025-04-06T13:30:46.130406Z","iopub.status.idle":"2025-04-06T13:30:46.190352Z","shell.execute_reply.started":"2025-04-06T13:30:46.130384Z","shell.execute_reply":"2025-04-06T13:30:46.189301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = \"/kaggle/input/tuberculosisxray/TB_Data\"\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Train\"), transform=train_transforms)\nval_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Validation\"), transform=val_test_transforms)\ntest_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Test\"), transform=val_test_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nclass_names = train_dataset.classes\nprint(f\"Classes: {class_names}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:31:12.832282Z","iopub.execute_input":"2025-04-06T13:31:12.832738Z","iopub.status.idle":"2025-04-06T13:31:20.010767Z","shell.execute_reply.started":"2025-04-06T13:31:12.832700Z","shell.execute_reply":"2025-04-06T13:31:20.009833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.resnext50_32x4d(pretrained=True)\n\n# Freeze feature extractor\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace classifier head\nmodel.fc = nn.Sequential(\n    nn.Linear(model.fc.in_features, 256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256, 2)\n)\n\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:33:27.348127Z","iopub.execute_input":"2025-04-06T13:33:27.348463Z","iopub.status.idle":"2025-04-06T13:33:28.920957Z","shell.execute_reply.started":"2025-04-06T13:33:27.348438Z","shell.execute_reply":"2025-04-06T13:33:28.920043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:33:38.746794Z","iopub.execute_input":"2025-04-06T13:33:38.747287Z","iopub.status.idle":"2025-04-06T13:33:38.753750Z","shell.execute_reply.started":"2025-04-06T13:33:38.747245Z","shell.execute_reply":"2025-04-06T13:33:38.752496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 15\ntrain_loss_history, val_loss_history = [], []\ntrain_acc_history, val_acc_history = [], []\n\nbest_val_loss = float('inf')\npatience, trigger_times = 3, 0  # early stopping\n\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    \n    # --- Training ---\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    \n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    train_loss_history.append(epoch_loss)\n    train_acc_history.append(epoch_acc)\n\n    # --- Validation ---\n    model.eval()\n    val_running_loss, val_correct, val_total = 0.0, 0, 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            val_running_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n    \n    val_loss = val_running_loss / val_total\n    val_acc = val_correct / val_total\n    val_loss_history.append(val_loss)\n    val_acc_history.append(val_acc)\n\n    print(f\"Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n    print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n\n   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:34:00.046037Z","iopub.execute_input":"2025-04-06T13:34:00.046396Z","iopub.status.idle":"2025-04-06T13:51:11.311535Z","shell.execute_reply.started":"2025-04-06T13:34:00.046369Z","shell.execute_reply":"2025-04-06T13:51:11.310369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs_range = range(len(train_loss_history))\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_loss_history, label='Train Loss')\nplt.plot(epochs_range, val_loss_history, label='Val Loss')\nplt.legend()\nplt.title(\"Loss Curve\")\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, train_acc_history, label='Train Accuracy')\nplt.plot(epochs_range, val_acc_history, label='Val Accuracy')\nplt.legend()\nplt.title(\"Accuracy Curve\")\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:52:04.274847Z","iopub.execute_input":"2025-04-06T13:52:04.275178Z","iopub.status.idle":"2025-04-06T13:52:04.700779Z","shell.execute_reply.started":"2025-04-06T13:52:04.275154Z","shell.execute_reply":"2025-04-06T13:52:04.699799Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model if it's the best one so far\nif val_loss < best_val_loss:\n    best_val_loss = val_loss\n    torch.save(model.state_dict(), \"best_resnext_model.pth\")\n    trigger_times = 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:55:08.872364Z","iopub.execute_input":"2025-04-06T13:55:08.872699Z","iopub.status.idle":"2025-04-06T13:55:09.028097Z","shell.execute_reply.started":"2025-04-06T13:55:08.872675Z","shell.execute_reply":"2025-04-06T13:55:09.027434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Load the best model saved earlier\nmodel.load_state_dict(torch.load(\"best_resnext_model.pth\"))\nmodel.eval()\n\ny_true = []\ny_pred = []\n\n# Disable gradient calculations during inference\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:55:17.455412Z","iopub.execute_input":"2025-04-06T13:55:17.455744Z","iopub.status.idle":"2025-04-06T13:55:27.367737Z","shell.execute_reply.started":"2025-04-06T13:55:17.455719Z","shell.execute_reply":"2025-04-06T13:55:27.366973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy\nacc = accuracy_score(y_true, y_pred)\nprint(f\"Test Accuracy: {acc:.4f}\")\n\n# Classification Report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\n# Confusion Matrix\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_true, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:55:58.972657Z","iopub.execute_input":"2025-04-06T13:55:58.973039Z","iopub.status.idle":"2025-04-06T13:55:58.990900Z","shell.execute_reply.started":"2025-04-06T13:55:58.973012Z","shell.execute_reply":"2025-04-06T13:55:58.989691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef imshow(inp, title=None):\n    inp = inp.permute(1, 2, 0).numpy()\n    mean = np.array([0.485, 0.456, 0.406])\n    std  = np.array([0.229, 0.224, 0.225])\n    inp  = std * inp + mean\n    inp  = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.axis(\"off\")\n\n# Show a few test images with predicted and true labels\ndataiter = iter(test_loader)\nimages, labels = next(dataiter)\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(images.to(device))\n    _, preds = torch.max(outputs, 1)\n\n# Plot first 5 images\nplt.figure(figsize=(12, 6))\nfor idx in range(5):\n    plt.subplot(1, 5, idx + 1)\n    imshow(images[idx].cpu(), title=f\"Pred: {class_names[preds[idx]]}\\nTrue: {class_names[labels[idx]]}\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:56:12.767070Z","iopub.execute_input":"2025-04-06T13:56:12.767353Z","iopub.status.idle":"2025-04-06T13:56:13.681719Z","shell.execute_reply.started":"2025-04-06T13:56:12.767333Z","shell.execute_reply":"2025-04-06T13:56:13.680787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"\\nBest Train Accuracy: {max(train_acc_history):.4f}\")\nprint(f\"Best Validation Accuracy: {max(val_acc_history):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:56:29.897533Z","iopub.execute_input":"2025-04-06T13:56:29.897906Z","iopub.status.idle":"2025-04-06T13:56:29.902995Z","shell.execute_reply.started":"2025-04-06T13:56:29.897880Z","shell.execute_reply":"2025-04-06T13:56:29.902254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Load best model\nmodel.load_state_dict(torch.load(\"best_resnext_model.pth\"))\nmodel.eval()\n\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\ntest_acc = accuracy_score(y_true, y_pred)\nprint(f\"\\nTest Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:56:40.279489Z","iopub.execute_input":"2025-04-06T13:56:40.279830Z","iopub.status.idle":"2025-04-06T13:56:47.371147Z","shell.execute_reply.started":"2025-04-06T13:56:40.279802Z","shell.execute_reply":"2025-04-06T13:56:47.370058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Final Accuracy Summary ---\")\nprint(f\"Train Accuracy      : {max(train_acc_history):.4f}\")\nprint(f\"Validation Accuracy : {max(val_acc_history):.4f}\")\nprint(f\"Test Accuracy       : {test_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:00:56.862358Z","iopub.execute_input":"2025-04-06T14:00:56.862695Z","iopub.status.idle":"2025-04-06T14:00:56.868678Z","shell.execute_reply.started":"2025-04-06T14:00:56.862669Z","shell.execute_reply":"2025-04-06T14:00:56.867691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After loading best model and running inference on test data\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:58:41.720226Z","iopub.execute_input":"2025-04-06T13:58:41.720618Z","iopub.status.idle":"2025-04-06T13:58:48.563599Z","shell.execute_reply.started":"2025-04-06T13:58:41.720563Z","shell.execute_reply":"2025-04-06T13:58:48.562876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Replace with your actual class names if needed\nclass_names = ['Normal', 'Tuberculosis']\n\n# Create confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Normalize (optional)\ncm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n# Plot confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n            xticklabels=class_names, yticklabels=class_names)\n\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Normalized Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:58:51.960518Z","iopub.execute_input":"2025-04-06T13:58:51.960996Z","iopub.status.idle":"2025-04-06T13:58:52.161895Z","shell.execute_reply.started":"2025-04-06T13:58:51.960964Z","shell.execute_reply":"2025-04-06T13:58:52.160966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n            xticklabels=class_names, yticklabels=class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:59:17.576706Z","iopub.execute_input":"2025-04-06T13:59:17.576994Z","iopub.status.idle":"2025-04-06T13:59:17.760337Z","shell.execute_reply.started":"2025-04-06T13:59:17.576973Z","shell.execute_reply":"2025-04-06T13:59:17.759644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if val_loss < best_val_loss:\n    best_val_loss = val_loss\n    torch.save(model.state_dict(), \"best_resnext_model.pth\")\n    print(\"✅ Model saved at best_val_loss:\", best_val_loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:03:52.444070Z","iopub.execute_input":"2025-04-06T14:03:52.444379Z","iopub.status.idle":"2025-04-06T14:03:52.448488Z","shell.execute_reply.started":"2025-04-06T14:03:52.444358Z","shell.execute_reply":"2025-04-06T14:03:52.447425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"final_resnext_model.pth\")\nprint(\"✅ Final model saved as 'final_resnext_model.pth'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:03:28.142798Z","iopub.execute_input":"2025-04-06T14:03:28.143156Z","iopub.status.idle":"2025-04-06T14:03:28.301667Z","shell.execute_reply.started":"2025-04-06T14:03:28.143126Z","shell.execute_reply":"2025-04-06T14:03:28.300886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n# Function to denormalize and display an image\ndef imshow(img, title=None):\n    img = img.cpu().numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std  = np.array([0.229, 0.224, 0.225])\n    img  = std * img + mean\n    img  = np.clip(img, 0, 1)\n    plt.imshow(img)\n    if title:\n        plt.title(title)\n    plt.axis('off')\n\n# Get a batch of test images\ndataiter = iter(test_loader)\nimages, labels = next(dataiter)\nimages = images.to(device)\nlabels = labels.to(device)\n\n# Predict\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\n\n# Define class names (adjust if yours are different)\nclass_names = ['Normal', 'Tuberculosis']\n\n# Visualize first 8 images\nplt.figure(figsize=(16, 8))\nfor idx in range(8):\n    ax = plt.subplot(2, 4, idx + 1)\n    correct = preds[idx] == labels[idx]\n    color = 'green' if correct else 'red'\n    \n    title = f\"Pred: {class_names[preds[idx]]}\\nTrue: {class_names[labels[idx]]}\"\n    imshow(images[idx], title=title)\n    plt.title(title, color=color, fontsize=10)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:19:15.887034Z","iopub.execute_input":"2025-04-06T14:19:15.887367Z","iopub.status.idle":"2025-04-06T14:19:17.542081Z","shell.execute_reply.started":"2025-04-06T14:19:15.887339Z","shell.execute_reply":"2025-04-06T14:19:17.541179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch\nimport os\n\n# ✅ Path to the uploaded image (change this)\nimage_path = '/kaggle/input/tuberculosisxray/TB_Data/Test/Normal/Normal-1278.png'\n\n# ✅ Automatically extract the true label from folder name\ntrue_label = os.path.basename(os.path.dirname(image_path))  # 'Normal' or 'Tuberculosis'\n\n# ✅ Load and preprocess the image\nimage = Image.open(image_path).convert('RGB')\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\n# ✅ Make prediction using your trained model\nmodel.eval()\nwith torch.no_grad():\n    output = model(input_tensor)\n    predicted_class = torch.argmax(output, 1).item()\n    confidence = torch.softmax(output, dim=1)[0][predicted_class].item() * 100\n\n# ✅ Class names\nclass_names = ['Normal', 'Tuberculosis']\npredicted_label = class_names[predicted_class]\n\n# ✅ Compare prediction and true label\nis_correct = (predicted_label == true_label)\nstatus = \"✅ Correct\" if is_correct else \"❌ Wrong\"\ncolor = 'green' if is_correct else 'red'\n\n# ✅ Print results\nprint(f\"Predicted Class: {predicted_label}\")\nprint(f\"Confidence: {confidence:.2f}%\")\nprint(f\"True Label: {true_label} → {status}\")\n\n# ✅ Show image with prediction info\nplt.imshow(image)\nplt.axis('off')\nplt.title(f\"Prediction: {predicted_label} ({confidence:.2f}%)\\nTrue: {true_label} → {status}\", \n          color=color, fontsize=12)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:37:56.823165Z","iopub.execute_input":"2025-04-06T14:37:56.823502Z","iopub.status.idle":"2025-04-06T14:37:57.012063Z","shell.execute_reply.started":"2025-04-06T14:37:56.823476Z","shell.execute_reply":"2025-04-06T14:37:57.011120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch\nimport os\n\n# ✅ Path to the uploaded image (change this)\nimage_path = '/kaggle/input/tuberculosisxray/TB_Data/Test/Tuberculosis/Tuberculosis-117.png'\n\n# ✅ Automatically extract the true label from folder name\ntrue_label = os.path.basename(os.path.dirname(image_path))  # 'Normal' or 'Tuberculosis'\n\n# ✅ Load and preprocess the image\nimage = Image.open(image_path).convert('RGB')\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\n# ✅ Make prediction using your trained model\nmodel.eval()\nwith torch.no_grad():\n    output = model(input_tensor)\n    predicted_class = torch.argmax(output, 1).item()\n    confidence = torch.softmax(output, dim=1)[0][predicted_class].item() * 100\n\n# ✅ Class names\nclass_names = ['Normal', 'Tuberculosis']\npredicted_label = class_names[predicted_class]\n\n# ✅ Compare prediction and true label\nis_correct = (predicted_label == true_label)\nstatus = \"✅ Correct\" if is_correct else \"❌ Wrong\"\ncolor = 'green' if is_correct else 'red'\n\n# ✅ Print results\nprint(f\"Predicted Class: {predicted_label}\")\nprint(f\"Confidence: {confidence:.2f}%\")\nprint(f\"True Label: {true_label} → {status}\")\n\n# ✅ Show image with prediction info\nplt.imshow(image)\nplt.axis('off')\nplt.title(f\"Prediction: {predicted_label} ({confidence:.2f}%)\\nTrue: {true_label} → {status}\", \n          color=color, fontsize=12)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T14:38:22.226070Z","iopub.execute_input":"2025-04-06T14:38:22.226359Z","iopub.status.idle":"2025-04-06T14:38:22.408040Z","shell.execute_reply.started":"2025-04-06T14:38:22.226338Z","shell.execute_reply":"2025-04-06T14:38:22.406990Z"}},"outputs":[],"execution_count":null}]}