{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11273081,"sourceType":"datasetVersion","datasetId":7047169}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 📦 1. Imports\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 📍 2. Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:20:58.827291Z","iopub.execute_input":"2025-04-06T06:20:58.827603Z","iopub.status.idle":"2025-04-06T06:20:58.833133Z","shell.execute_reply.started":"2025-04-06T06:20:58.827575Z","shell.execute_reply":"2025-04-06T06:20:58.832068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🧹 3. Data preparation and augmentation\ndata_dir = \"/kaggle/input/tuberculosisdatas/TB_Data\"\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = datasets.ImageFolder(os.path.join(data_dir, \"Train\"), transform=train_transforms)\nval_dataset   = datasets.ImageFolder(os.path.join(data_dir, \"Validation\"), transform=val_test_transforms)\ntest_dataset  = datasets.ImageFolder(os.path.join(data_dir, \"Test\"), transform=val_test_transforms)\n2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:21:01.63803Z","iopub.execute_input":"2025-04-06T06:21:01.638333Z","iopub.status.idle":"2025-04-06T06:21:04.096202Z","shell.execute_reply.started":"2025-04-06T06:21:01.638311Z","shell.execute_reply":"2025-04-06T06:21:04.095466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ⚖️ 4. Handle class imbalance with WeightedRandomSampler\nclass_counts = [0] * len(train_dataset.classes)\nfor _, label in train_dataset:\n    class_counts[label] += 1\n\nclass_weights = [1.0 / class_counts[label] for _, label in train_dataset]\nsampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:21:06.07303Z","iopub.execute_input":"2025-04-06T06:21:06.073374Z","iopub.status.idle":"2025-04-06T06:22:43.676538Z","shell.execute_reply.started":"2025-04-06T06:21:06.073346Z","shell.execute_reply":"2025-04-06T06:22:43.675821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 📦 5. DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\nval_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:22:52.048943Z","iopub.execute_input":"2025-04-06T06:22:52.049258Z","iopub.status.idle":"2025-04-06T06:22:52.053875Z","shell.execute_reply.started":"2025-04-06T06:22:52.049234Z","shell.execute_reply":"2025-04-06T06:22:52.052896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🧠 6. Load ConvNeXt-Tiny and modify classifier\nmodel = models.convnext_tiny(pretrained=True)\nfor param in model.features.parameters():\n    param.requires_grad = False  # Freeze backbone\n\n# Modify classifier\nmodel.classifier[2] = nn.Linear(model.classifier[2].in_features, 2)\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:22:55.894189Z","iopub.execute_input":"2025-04-06T06:22:55.894484Z","iopub.status.idle":"2025-04-06T06:22:57.35675Z","shell.execute_reply.started":"2025-04-06T06:22:55.894462Z","shell.execute_reply":"2025-04-06T06:22:57.355853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🧮 7. Loss, optimizer, scheduler\n# Weighted loss for imbalance\nweights = torch.tensor([1.0 / class_counts[0], 1.0 / class_counts[1]], device=device)\ncriterion = nn.CrossEntropyLoss(weight=weights)\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:23:00.751108Z","iopub.execute_input":"2025-04-06T06:23:00.751443Z","iopub.status.idle":"2025-04-06T06:23:00.757567Z","shell.execute_reply.started":"2025-04-06T06:23:00.751416Z","shell.execute_reply":"2025-04-06T06:23:00.756655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 🔁 8. Training loop with validation\nnum_epochs = 50\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = correct / total\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    # Validation\n    model.eval()\n    val_loss, val_correct, val_total = 0.0, 0, 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_loss = val_loss / len(val_loader)\n    val_acc = val_correct / val_total\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n\n    scheduler.step()\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] => Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:23:13.252121Z","iopub.execute_input":"2025-04-06T06:23:13.252459Z","iopub.status.idle":"2025-04-06T07:18:13.812315Z","shell.execute_reply.started":"2025-04-06T06:23:13.252434Z","shell.execute_reply":"2025-04-06T07:18:13.811376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 📈 9. Plotting loss and accuracy curves\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label=\"Train Loss\")\nplt.plot(val_losses, label=\"Validation Loss\")\nplt.title(\"Loss Curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label=\"Train Accuracy\")\nplt.plot(val_accuracies, label=\"Validation Accuracy\")\nplt.title(\"Accuracy Curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:19:18.730488Z","iopub.execute_input":"2025-04-06T07:19:18.730809Z","iopub.status.idle":"2025-04-06T07:19:19.217442Z","shell.execute_reply.started":"2025-04-06T07:19:18.730785Z","shell.execute_reply":"2025-04-06T07:19:19.216515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import (\n    confusion_matrix, classification_report, roc_curve,\n    roc_auc_score, accuracy_score, precision_score,\n    recall_score, f1_score\n)\nimport seaborn as sns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:19:30.540653Z","iopub.execute_input":"2025-04-06T07:19:30.540972Z","iopub.status.idle":"2025-04-06T07:19:31.290814Z","shell.execute_reply.started":"2025-04-06T07:19:30.540946Z","shell.execute_reply":"2025-04-06T07:19:31.290137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nall_labels = []\nall_preds = []\nall_probs = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        probs = torch.softmax(outputs, dim=1)[:, 1]  # Probabilities for class \"Tuberculosis\"\n        _, predicted = torch.max(outputs, 1)\n        \n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(predicted.cpu().numpy())\n        all_probs.extend(probs.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:19:34.544236Z","iopub.execute_input":"2025-04-06T07:19:34.544666Z","iopub.status.idle":"2025-04-06T07:19:51.065176Z","shell.execute_reply.started":"2025-04-06T07:19:34.544641Z","shell.execute_reply":"2025-04-06T07:19:51.064507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"📋 Classification Report:\\n\")\nprint(classification_report(all_labels, all_preds, target_names=train_dataset.classes))\n\nacc  = accuracy_score(all_labels, all_preds)\nprec = precision_score(all_labels, all_preds)\nrec  = recall_score(all_labels, all_preds)\nf1   = f1_score(all_labels, all_preds)\nauc  = roc_auc_score(all_labels, all_probs)\n\nprint(f\"✅ Accuracy:  {acc:.4f}\")\nprint(f\"✅ Precision: {prec:.4f}\")\nprint(f\"✅ Recall:    {rec:.4f}\")\nprint(f\"✅ F1 Score:  {f1:.4f}\")\nprint(f\"✅ AUC Score: {auc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:19:55.098826Z","iopub.execute_input":"2025-04-06T07:19:55.099127Z","iopub.status.idle":"2025-04-06T07:19:55.126576Z","shell.execute_reply.started":"2025-04-06T07:19:55.099105Z","shell.execute_reply":"2025-04-06T07:19:55.125851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:20:02.376441Z","iopub.execute_input":"2025-04-06T07:20:02.376751Z","iopub.status.idle":"2025-04-06T07:20:02.555786Z","shell.execute_reply.started":"2025-04-06T07:20:02.376727Z","shell.execute_reply":"2025-04-06T07:20:02.5549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(all_labels, all_probs)\nplt.figure(figsize=(6, 5))\nplt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:20:07.18584Z","iopub.execute_input":"2025-04-06T07:20:07.186138Z","iopub.status.idle":"2025-04-06T07:20:07.359484Z","shell.execute_reply.started":"2025-04-06T07:20:07.186116Z","shell.execute_reply":"2025-04-06T07:20:07.358604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_accuracy(model, dataloader, name=\"Dataset\"):\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    acc = 100 * correct / total\n    print(f\"✅ {name} Accuracy: {acc:.2f}%\")\n    return acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:20:11.19245Z","iopub.execute_input":"2025-04-06T07:20:11.19278Z","iopub.status.idle":"2025-04-06T07:20:11.197811Z","shell.execute_reply.started":"2025-04-06T07:20:11.19275Z","shell.execute_reply":"2025-04-06T07:20:11.196894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_acc_percent = get_accuracy(model, train_loader, \"Train\")\nval_acc_percent   = get_accuracy(model, val_loader, \"Validation\")\ntest_acc_percent  = get_accuracy(model, test_loader, \"Test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:20:15.923416Z","iopub.execute_input":"2025-04-06T07:20:15.923699Z","iopub.status.idle":"2025-04-06T07:21:29.041934Z","shell.execute_reply.started":"2025-04-06T07:20:15.923678Z","shell.execute_reply":"2025-04-06T07:21:29.040941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch\n\n# Path to the uploaded image\nimage_path = '/kaggle/input/tuberculosisdatas/TB_Data/Test/Normal/Normal-1047.png'  # 👈 Change if needed\n\n# Load and preprocess the image\nimage = Image.open(image_path).convert('RGB')\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])  # ✅ Matches ConvNeXt training\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\n# Make prediction\nmodel.eval()  # Use ConvNeXt model here\nwith torch.no_grad():\n    output = model(input_tensor)\n    predicted_class = torch.argmax(output, 1).item()\n    confidence = torch.softmax(output, dim=1)[0][predicted_class].item() * 100\n\n# Class names (based on ImageFolder)\nclass_names = ['Normal', 'Tuberculosis']\n\n# Output results\nprint(f\"✅ Predicted Class: {class_names[predicted_class]}\")\nprint(f\"🔢 Confidence: {confidence:.2f}%\")\n\n# Show the image with prediction\nplt.imshow(image)\nplt.axis('off')\nplt.title(f\"Prediction: {class_names[predicted_class]} ({confidence:.2f}%)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:21:32.166445Z","iopub.execute_input":"2025-04-06T07:21:32.166746Z","iopub.status.idle":"2025-04-06T07:21:32.355676Z","shell.execute_reply.started":"2025-04-06T07:21:32.166723Z","shell.execute_reply":"2025-04-06T07:21:32.354726Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nimport torch\n\n# Path to the uploaded image\nimage_path = '/kaggle/input/tuberculosisdatas/TB_Data/Test/Tuberculosis/Tuberculosis-121.png'  # 👈 Change if needed\n\n# Load and preprocess the image\nimage = Image.open(image_path).convert('RGB')\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], \n                         [0.229, 0.224, 0.225])  # ✅ Matches ConvNeXt training\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n\n# Make prediction\nmodel.eval()  # Use ConvNeXt model here\nwith torch.no_grad():\n    output = model(input_tensor)\n    predicted_class = torch.argmax(output, 1).item()\n    confidence = torch.softmax(output, dim=1)[0][predicted_class].item() * 100\n\n# Class names (based on ImageFolder)\nclass_names = ['Normal', 'Tuberculosis']\n\n# Output results\nprint(f\"✅ Predicted Class: {class_names[predicted_class]}\")\nprint(f\"🔢 Confidence: {confidence:.2f}%\")\n\n# Show the image with prediction\nplt.imshow(image)\nplt.axis('off')\nplt.title(f\"Prediction: {class_names[predicted_class]} ({confidence:.2f}%)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:21:37.197443Z","iopub.execute_input":"2025-04-06T07:21:37.197735Z","iopub.status.idle":"2025-04-06T07:21:37.347174Z","shell.execute_reply.started":"2025-04-06T07:21:37.197711Z","shell.execute_reply":"2025-04-06T07:21:37.346373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the entire model\ntorch.save(model.state_dict(), 'convnext_tiny_tb.pth')\nprint(\"✅ Model saved as 'convnext_tiny_tb.pth'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:21:41.928423Z","iopub.execute_input":"2025-04-06T07:21:41.928744Z","iopub.status.idle":"2025-04-06T07:21:42.093365Z","shell.execute_reply.started":"2025-04-06T07:21:41.928719Z","shell.execute_reply":"2025-04-06T07:21:42.092499Z"}},"outputs":[],"execution_count":null}]}