{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11272197,"sourceType":"datasetVersion","datasetId":7046488}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.models.vision_transformer import vit_b_16, ViT_B_16_Weights\n\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:28:59.710226Z","iopub.execute_input":"2025-04-06T07:28:59.710606Z","iopub.status.idle":"2025-04-06T07:28:59.715431Z","shell.execute_reply.started":"2025-04-06T07:28:59.710576Z","shell.execute_reply":"2025-04-06T07:28:59.714532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transforms\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Directories\nbase_dir = '/kaggle/input/tuberculosisdata/TB_Data'\ntrain_dir = os.path.join(base_dir, 'Train')\nval_dir = os.path.join(base_dir, 'Validation')\ntest_dir = os.path.join(base_dir, 'Test')\n\n# Datasets & Dataloaders\ntrain_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\nval_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)\ntest_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nclass_names = train_dataset.classes\nprint(\"âœ… Classes:\", class_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:29:04.429574Z","iopub.execute_input":"2025-04-06T07:29:04.429894Z","iopub.status.idle":"2025-04-06T07:29:09.852935Z","shell.execute_reply.started":"2025-04-06T07:29:04.429864Z","shell.execute_reply":"2025-04-06T07:29:09.852028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load pretrained ViT\nvit_model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n\n# Modify classifier for binary classification\nin_features = vit_model.heads[0].in_features\nvit_model.heads = nn.Sequential(nn.Linear(in_features, 2))\nvit_model = vit_model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:29:27.459569Z","iopub.execute_input":"2025-04-06T07:29:27.459895Z","iopub.status.idle":"2025-04-06T07:29:30.861833Z","shell.execute_reply.started":"2025-04-06T07:29:27.45987Z","shell.execute_reply":"2025-04-06T07:29:30.861144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Base dataset path\nbase_path = \"/kaggle/input/tuberculosisdata/TB_Data\"\n\n# Function to count images in each subfolder\ndef count_images(folder_path):\n    counts = {}\n    for class_name in os.listdir(folder_path):\n        class_path = os.path.join(folder_path, class_name)\n        if os.path.isdir(class_path):\n            num_images = len(os.listdir(class_path))\n            counts[class_name] = num_images\n    return counts\n\n# Count for Train, Validation, Test\ntrain_counts = count_images(os.path.join(base_path, \"Train\"))\nval_counts = count_images(os.path.join(base_path, \"Validation\"))\ntest_counts = count_images(os.path.join(base_path, \"Test\"))\n\n# Print the results\nprint(\"ðŸ“Š Train Set Image Counts:\", train_counts)\nprint(\"ðŸ“Š Validation Set Image Counts:\", val_counts)\nprint(\"ðŸ“Š Test Set Image Counts:\", test_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:30:14.750417Z","iopub.execute_input":"2025-04-06T07:30:14.750751Z","iopub.status.idle":"2025-04-06T07:30:14.767271Z","shell.execute_reply.started":"2025-04-06T07:30:14.750723Z","shell.execute_reply":"2025-04-06T07:30:14.766558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute class weights\nclass_counts = [len(os.listdir(os.path.join(train_dir, c))) for c in class_names]\nweights = 1. / torch.tensor(class_counts, dtype=torch.float)\nweighted_loss = nn.CrossEntropyLoss(weight=weights.to(device))\n\n# Optimizer\noptimizer = torch.optim.Adam(vit_model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:30:19.801176Z","iopub.execute_input":"2025-04-06T07:30:19.801518Z","iopub.status.idle":"2025-04-06T07:30:19.811251Z","shell.execute_reply.started":"2025-04-06T07:30:19.801487Z","shell.execute_reply":"2025-04-06T07:30:19.810341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, loader, criterion):\n    model.eval()\n    val_loss, correct, total = 0.0, 0, 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return val_loss / len(loader), correct / total\n\n# Store metrics for plotting\ntrain_losses, val_losses = [], []\ntrain_accuracies, val_accuracies = [], []\n\ndef train_model(model, criterion, optimizer, train_loader, val_loader, epochs=20):\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n        avg_train_loss = running_loss / len(train_loader)\n        train_acc = correct / total\n        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n\n        train_losses.append(avg_train_loss)\n        val_losses.append(val_loss)\n        train_accuracies.append(train_acc)\n        val_accuracies.append(val_acc)\n\n        print(f\"ðŸ“‰ Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        print(f\"ðŸ“ˆ Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n        # Save best model (optional, still kept)\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), \"best_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:30:28.200453Z","iopub.execute_input":"2025-04-06T07:30:28.200768Z","iopub.status.idle":"2025-04-06T07:30:28.209118Z","shell.execute_reply.started":"2025-04-06T07:30:28.200743Z","shell.execute_reply":"2025-04-06T07:30:28.208357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(vit_model, weighted_loss, optimizer, train_loader, val_loader, epochs=50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T07:30:35.509865Z","iopub.execute_input":"2025-04-06T07:30:35.510159Z","iopub.status.idle":"2025-04-06T09:49:18.364627Z","shell.execute_reply.started":"2025-04-06T07:30:35.510136Z","shell.execute_reply":"2025-04-06T09:49:18.363711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load best model\nvit_model.load_state_dict(torch.load(\"best_model.pth\"))\nvit_model.eval()\n\nall_preds, all_labels, all_probs = [], [], []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        outputs = vit_model(images)\n        probs = torch.softmax(outputs, dim=1)\n        _, preds = torch.max(outputs, 1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.numpy())\n        all_probs.extend(probs[:, 1].cpu().numpy())\n\n# Confusion Matrix\ncm = confusion_matrix(all_labels, all_preds)\ndisp = ConfusionMatrixDisplay(cm, display_labels=class_names)\ndisp.plot(cmap='Blues', values_format='d')\nplt.title(\"ðŸ§ª Confusion Matrix on Test Set\")\nplt.show()\n\n# Classification Report\nprint(\"ðŸ“‹ Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=class_names))\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(all_labels, all_probs)\nroc_auc = roc_auc_score(all_labels, all_probs)\n\nplt.figure(figsize=(8,6))\nplt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve - Vision Transformer\")\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:53:10.051665Z","iopub.execute_input":"2025-04-06T09:53:10.051962Z","iopub.status.idle":"2025-04-06T09:53:23.470533Z","shell.execute_reply.started":"2025-04-06T09:53:10.051939Z","shell.execute_reply":"2025-04-06T09:53:23.469387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy Curve\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\nplt.legend()\nplt.grid()\nplt.show()\n\n# Loss Curve\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Model Loss')\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:53:35.940869Z","iopub.execute_input":"2025-04-06T09:53:35.94116Z","iopub.status.idle":"2025-04-06T09:53:36.461739Z","shell.execute_reply.started":"2025-04-06T09:53:35.941138Z","shell.execute_reply":"2025-04-06T09:53:36.460867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"ðŸ“Š Accuracy per Epoch:\")\nprint(f\"{'Epoch':<6} {'Train Accuracy (%)':<20} {'Val Accuracy (%)':<20}\")\nprint(\"-\" * 50)\n\nfor epoch, (train_acc, val_acc) in enumerate(zip(train_accuracies, val_accuracies), start=1):\n    print(f\"{epoch:<6} {train_acc * 100:<20.2f} {val_acc * 100:<20.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T09:09:43.744237Z","iopub.execute_input":"2025-04-04T09:09:43.744593Z","iopub.status.idle":"2025-04-04T09:09:43.751297Z","shell.execute_reply.started":"2025-04-04T09:09:43.744562Z","shell.execute_reply":"2025-04-04T09:09:43.750613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef get_final_accuracy(model, loader, set_name=\"Set\"):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    acc = accuracy_score(all_labels, all_preds)\n    print(f\"âœ… Final Accuracy on {set_name}: {acc * 100:.2f}%\")\n    return acc * 100\n\n# Make sure your best model is loaded\nvit_model.load_state_dict(torch.load(\"best_model.pth\"))\n\n# Calculate accuracies\nfinal_train_acc = get_final_accuracy(vit_model, train_loader, \"Train Set\")\nfinal_val_acc = get_final_accuracy(vit_model, val_loader, \"Validation Set\")\nfinal_test_acc = get_final_accuracy(vit_model, test_loader, \"Test Set\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:54:17.962383Z","iopub.execute_input":"2025-04-06T09:54:17.962772Z","iopub.status.idle":"2025-04-06T09:56:05.946006Z","shell.execute_reply.started":"2025-04-06T09:54:17.962744Z","shell.execute_reply":"2025-04-06T09:56:05.94523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the uploaded image\nimage_path = '/kaggle/input/tuberculosisdata/TB_Data/Test/Normal/Normal-1009.png'  # change this if needed\n\n# Load and preprocess the image\nimage = Image.open(image_path).convert('RGB')\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)\n\n# Load your trained model\nvit_model.eval()\nwith torch.no_grad():\n    output = vit_model(input_tensor)\n    predicted_class = torch.argmax(output, 1).item()\n\n# Class names (ensure it matches your training dataset)\nclass_names = ['Normal', 'Tuberculosis']\nprint(f\"âœ… Predicted Class: {class_names[predicted_class]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:56:18.222937Z","iopub.execute_input":"2025-04-06T09:56:18.223253Z","iopub.status.idle":"2025-04-06T09:56:18.274934Z","shell.execute_reply.started":"2025-04-06T09:56:18.223224Z","shell.execute_reply":"2025-04-06T09:56:18.274248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(image)\nplt.axis('off')\nplt.title(f\"Prediction: {class_names[predicted_class]}\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:56:23.302881Z","iopub.execute_input":"2025-04-06T09:56:23.303161Z","iopub.status.idle":"2025-04-06T09:56:23.437221Z","shell.execute_reply.started":"2025-04-06T09:56:23.303139Z","shell.execute_reply":"2025-04-06T09:56:23.436395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the uploaded image\nimage_path = '/kaggle/input/tuberculosisdata/TB_Data/Test/Tuberculosis/Tuberculosis-113_aug0.png'  # change this if needed\n\n# Load and preprocess the image\nimage = Image.open(image_path).convert('RGB')\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ninput_tensor = transform(image).unsqueeze(0).to(device)\n\n# Load your trained model\nvit_model.eval()\nwith torch.no_grad():\n    output = vit_model(input_tensor)\n    predicted_class = torch.argmax(output, 1).item()\n\n# Class names (ensure it matches your training dataset)\nclass_names = ['Normal', 'Tuberculosis']\nprint(f\"âœ… Predicted Class: {class_names[predicted_class]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:56:26.729849Z","iopub.execute_input":"2025-04-06T09:56:26.73021Z","iopub.status.idle":"2025-04-06T09:56:26.753893Z","shell.execute_reply.started":"2025-04-06T09:56:26.730162Z","shell.execute_reply":"2025-04-06T09:56:26.753053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(image)\nplt.axis('off')\nplt.title(f\"Prediction: {class_names[predicted_class]}\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T09:56:29.421759Z","iopub.execute_input":"2025-04-06T09:56:29.422042Z","iopub.status.idle":"2025-04-06T09:56:29.549666Z","shell.execute_reply.started":"2025-04-06T09:56:29.422019Z","shell.execute_reply":"2025-04-06T09:56:29.548811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the entire model (architecture + weights)\ntorch.save(vit_model, \"vit_full_model.pth\")\nprint(\"âœ… ViT model saved as vit_full_model.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}